{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d246db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import Accuracy, AUROC, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db45dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_shape=(128, 128, 128)):\n",
    "        self.df = dataframe\n",
    "        self.image_paths = self.df['ADNI_path'].values\n",
    "        self.labels = self.df['Group'].values\n",
    "\n",
    "        # Binary classification mapping\n",
    "        self.label_names = {'CN': 0, 'AD': 1, \"MCI\": 2, \"EMCI\": 3, \"LMCI\": 4}\n",
    "        self.num_classes = len(self.label_names)\n",
    "        self.labels_binary = self.df['Group'].map(self.label_names).values\n",
    "        \n",
    "        print(f\"{len(self.image_paths)} Images found with classification.\")\n",
    "        print(f\"Samples per class: {dict(zip(*np.unique(self.labels, return_counts=True)))}\")\n",
    "        \n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def resize_image(self, image_np):\n",
    "        \"\"\" Resize the numpy image using scipy.ndimage.zoom \"\"\"\n",
    "        from scipy.ndimage import zoom\n",
    "        scale_factors = [n/o for n, o in zip(self.img_shape, image_np.shape)]\n",
    "        resized_image_np = zoom(image_np, scale_factors, order=1)  # Linear interpolation\n",
    "        return resized_image_np\n",
    "    \n",
    "    def crop_image_to_mask(self, image_volume):\n",
    "\n",
    "        # Find non-zero indices in the mask\n",
    "        non_zero_indices = np.argwhere(image_volume > 0)\n",
    "        if non_zero_indices.size == 0:\n",
    "            raise ValueError(\"Mask volume contains no non-zero values.\")\n",
    "\n",
    "        # Calculate bounding box\n",
    "        min_indices = np.min(non_zero_indices, axis=0)\n",
    "        max_indices = np.max(non_zero_indices, axis=0)\n",
    "\n",
    "        # Crop image\n",
    "        cropped_image = image_volume[\n",
    "            min_indices[0]:max_indices[0] + 1,\n",
    "            min_indices[1]:max_indices[1] + 1,\n",
    "            min_indices[2]:max_indices[2] + 1\n",
    "        ]\n",
    "\n",
    "        return cropped_image\n",
    "    \n",
    "    def process_image_only(self, image_path):\n",
    "        try:\n",
    "            \n",
    "            image_nib = nib.load(image_path)\n",
    "            image_np = image_nib.get_fdata()\n",
    "\n",
    "            image_np = self.crop_image_to_mask(image_np)\n",
    "\n",
    "            # Resize image\n",
    "            resized_image_np = self.resize_image(image_np)\n",
    "\n",
    "            # Normalize image\n",
    "            mean = np.mean(resized_image_np)\n",
    "            std = np.std(resized_image_np)\n",
    "            std = std if std != 0 else 1e-6\n",
    "            resized_image_np = (resized_image_np - mean) / std\n",
    "\n",
    "            # Convert to PyTorch tensor\n",
    "            image_tensor = torch.tensor(resized_image_np, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            return image_tensor\n",
    "        \n",
    "        except Exception as e:\n",
    "                return None\n",
    "\n",
    "    def process_image(self, idx):\n",
    "        try:\n",
    "            image_path = self.image_paths[idx]\n",
    "            label = self.labels_binary[idx]\n",
    "\n",
    "            # Load image using nibabel\n",
    "            image_nib = nib.load(image_path)\n",
    "            image_np = image_nib.get_fdata()\n",
    "\n",
    "            image_np = self.crop_image_to_mask(image_np)\n",
    "\n",
    "            # Resize image\n",
    "            resized_image_np = self.resize_image(image_np)\n",
    "\n",
    "            # Normalize image\n",
    "            mean = np.mean(resized_image_np)\n",
    "            std = np.std(resized_image_np)\n",
    "            std = std if std != 0 else 1e-6\n",
    "            resized_image_np = (resized_image_np - mean) / std\n",
    "\n",
    "            # Convert to PyTorch tensor\n",
    "            image_tensor = torch.tensor(resized_image_np, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            return image_tensor, label, image_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Exception in processing image {image_path}: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl, image_path = self.process_image(idx)\n",
    "        return img, lbl, image_path\n",
    "    \n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Remove samples that are None\n",
    "    batch = [item for item in batch if item[0] is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None  # or raise an error\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78bd9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group\n",
      "CN      1765\n",
      "EMCI    1394\n",
      "LMCI     857\n",
      "AD       776\n",
      "MCI      717\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total records processed: 5509\n",
      "Number of matched images: 5495\n",
      "Number of missing images: 14\n",
      "\n",
      "Group distribution in filtered dataset:\n",
      "Group\n",
      "CN      1761\n",
      "EMCI    1390\n",
      "LMCI     851\n",
      "AD       776\n",
      "MCI      717\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "      <th>ADNI_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1293299</td>\n",
       "      <td>130_S_4294</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>F</td>\n",
       "      <td>81</td>\n",
       "      <td>init</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MT1; N3m</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/31/2017</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/130_S_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I1293312</td>\n",
       "      <td>130_S_4294</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>F</td>\n",
       "      <td>81</td>\n",
       "      <td>init</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MT1; N3m</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/31/2017</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/130_S_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I966298</td>\n",
       "      <td>014_S_2308</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>init</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MT1; GradWarp; N3m</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/01/2017</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/014_S_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I966296</td>\n",
       "      <td>014_S_2308</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>init</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MT1; N3m</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/01/2017</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/014_S_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I1293301</td>\n",
       "      <td>018_S_4399</td>\n",
       "      <td>CN</td>\n",
       "      <td>F</td>\n",
       "      <td>84</td>\n",
       "      <td>init</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MT1; N3m</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/08/2017</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/018_S_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>I387751</td>\n",
       "      <td>011_S_0016</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HHP 6 DOF AC-PC registered MPRAGE</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/27/2005</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>I412371</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HHP 6 DOF AC-PC registered MPRAGE</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/02/2005</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>I474708</td>\n",
       "      <td>011_S_0005</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HarP 135 final release 2015</td>\n",
       "      <td>Processed</td>\n",
       "      <td>9/02/2005</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>I474758</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HarP 135 final release 2015</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/26/2005</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>I387749</td>\n",
       "      <td>011_S_0002</td>\n",
       "      <td>CN</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>sc</td>\n",
       "      <td>MRI</td>\n",
       "      <td>HHP 6 DOF AC-PC registered MPRAGE</td>\n",
       "      <td>Processed</td>\n",
       "      <td>8/26/2005</td>\n",
       "      <td>NiFTI</td>\n",
       "      <td>3/04/2025</td>\n",
       "      <td>C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5495 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image Data ID     Subject Group Sex  Age Visit Modality  \\\n",
       "0         I1293299  130_S_4294  LMCI   F   81  init      MRI   \n",
       "1         I1293312  130_S_4294  LMCI   F   81  init      MRI   \n",
       "2          I966298  014_S_2308  EMCI   M   81  init      MRI   \n",
       "3          I966296  014_S_2308  EMCI   M   81  init      MRI   \n",
       "4         I1293301  018_S_4399    CN   F   84  init      MRI   \n",
       "...            ...         ...   ...  ..  ...   ...      ...   \n",
       "5504       I387751  011_S_0016    CN   M   66    sc      MRI   \n",
       "5505       I412371  011_S_0005    CN   M   74    sc      MRI   \n",
       "5506       I474708  011_S_0005    CN   M   74    sc      MRI   \n",
       "5507       I474758  011_S_0002    CN   M   74    sc      MRI   \n",
       "5508       I387749  011_S_0002    CN   M   74    sc      MRI   \n",
       "\n",
       "                            Description       Type    Acq Date Format  \\\n",
       "0                              MT1; N3m  Processed  10/31/2017  NiFTI   \n",
       "1                              MT1; N3m  Processed  10/31/2017  NiFTI   \n",
       "2                    MT1; GradWarp; N3m  Processed   9/01/2017  NiFTI   \n",
       "3                              MT1; N3m  Processed   9/01/2017  NiFTI   \n",
       "4                              MT1; N3m  Processed   8/08/2017  NiFTI   \n",
       "...                                 ...        ...         ...    ...   \n",
       "5504  HHP 6 DOF AC-PC registered MPRAGE  Processed   9/27/2005  NiFTI   \n",
       "5505  HHP 6 DOF AC-PC registered MPRAGE  Processed   9/02/2005  NiFTI   \n",
       "5506        HarP 135 final release 2015  Processed   9/02/2005  NiFTI   \n",
       "5507        HarP 135 final release 2015  Processed   8/26/2005  NiFTI   \n",
       "5508  HHP 6 DOF AC-PC registered MPRAGE  Processed   8/26/2005  NiFTI   \n",
       "\n",
       "     Downloaded                                          ADNI_path  \n",
       "0     3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/130_S_4...  \n",
       "1     3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/130_S_4...  \n",
       "2     3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/014_S_2...  \n",
       "3     3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/014_S_2...  \n",
       "4     3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/018_S_4...  \n",
       "...         ...                                                ...  \n",
       "5504  3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...  \n",
       "5505  3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...  \n",
       "5506  3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...  \n",
       "5507  3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...  \n",
       "5508  3/04/2025  C:/ADNI_2/other_dataset/ADNI_processed/011_S_0...  \n",
       "\n",
       "[5495 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = 'C:/ADNI_2/other_dataset/ADNI_processed/'\n",
    "label_names = {'CN': 0, 'AD': 1, \"MCI\": 2, \"EMCI\": 3, \"LMCI\": 4}\n",
    "\n",
    "# fix this to be specific about data\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH = 128, 128, 128\n",
    "\n",
    "################################################################################################################\n",
    "def load_nii_paths(directory):\n",
    "    image_files = []\n",
    "    IDs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.nii.gz'):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "                IDs.append(os.path.join(root, file).split(\"\\\\\")[-2])\n",
    "                \n",
    "    return np.array(image_files), np.array(IDs)\n",
    "\n",
    "img_file_ori_2, IDs_2 = load_nii_paths(directory_path)\n",
    "\n",
    "################################################################################################################\n",
    "#  Load the CSV file\n",
    "df_2 = pd.read_csv(\"C:/ADNI_2/other_dataset/ADNI-2025.csv\")\n",
    "\n",
    "print(df_2[\"Group\"].value_counts())\n",
    "\n",
    "################################################################################################################\n",
    "# Add the paths to the csv file and create filtered dataframe\n",
    "main_imgs_2 = []\n",
    "valid_indices_2 = []\n",
    "\n",
    "for i in range(len(df_2)):\n",
    "    img_id = df_2[\"Image Data ID\"][i]\n",
    "    \n",
    "    try:\n",
    "        # Check if img_id exists in IDs array\n",
    "        matches = np.where(IDs_2 == img_id)[0]\n",
    "        if len(matches) == 0:\n",
    "            main_imgs_2.append(None)\n",
    "            continue\n",
    "            \n",
    "        index = matches[0]\n",
    "        main_imgs_2.append(img_file_ori_2[index])\n",
    "        valid_indices_2.append(i)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image ID {img_id}: {str(e)}\")\n",
    "        main_imgs_2.append(None)\n",
    "\n",
    "# Create new dataframe with only valid image data\n",
    "df_2[\"ADNI_path\"] = main_imgs_2\n",
    "df_valid = df_2.iloc[valid_indices_2].copy()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nTotal records processed: {len(df_2)}\")\n",
    "print(f\"Number of matched images: {len(df_valid)}\")\n",
    "print(f\"Number of missing images: {len(df_2) - len(df_valid)}\")\n",
    "\n",
    "print(\"\\nGroup distribution in filtered dataset:\")\n",
    "print(df_valid[\"Group\"].value_counts())\n",
    "\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a27a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5495 Images found with classification.\n",
      "Samples per class: {'AD': 776, 'CN': 1761, 'EMCI': 1390, 'LMCI': 851, 'MCI': 717}\n"
     ]
    }
   ],
   "source": [
    "img_size = (128, 128, 128, 1)\n",
    "\n",
    "train_dataset = CustomDataset(df_valid, img_shape=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e740a157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/ADNI_2/other_dataset/ADNI_processed/941_S_6052\\\\MT1__N3m\\\\2017-07-20_11_10_10.0\\\\I882756\\\\ADNI_941_S_6052_MR_MT1__N3m_Br_20170804183926749_S585807_I882756.nii.gz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdd2c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 171/5495 [00:54<23:48,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 727/5495 [03:52<22:20,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 857/5495 [04:36<26:14,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 865/5495 [04:39<25:31,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1471/5495 [07:55<20:59,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2033/5495 [10:48<18:06,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 2825/5495 [15:11<15:27,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 3102/5495 [16:46<13:46,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 3503/5495 [18:54<10:54,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3757/5495 [20:17<10:17,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4711/5495 [25:23<04:07,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image at C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5495/5495 [29:27<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df_valid))):\n",
    "    # Save the processed image tensor to a file\n",
    "    try:\n",
    "        img_path  = df_valid['ADNI_path'].iloc[i]\n",
    "        img = train_dataset.process_image_only(img_path)\n",
    "        if img is not None:\n",
    "            output_path = img_path.replace(\"\\\\\", \"/\").replace(\"ADNI_processed\", \"ADNI_tensors\").replace('.nii.gz', '.pt')\n",
    "            output_dir = os.path.dirname(output_path)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            torch.save(img.squeeze(0), output_path)\n",
    "        else:\n",
    "            print(f\"Skipping image at {img_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image at {output_path}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_mohammad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
